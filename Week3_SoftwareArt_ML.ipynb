{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week3_SoftwareArt_ML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP43Cetob9w8YbwghOFp2+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ak7588/SoftwareArt/blob/main/Week3_SoftwareArt_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiOHSsyY3woI"
      },
      "source": [
        "## Absurdism Philosophy Text Generator\n",
        "### Inspired by Albert Camus' \"The Myth of Sisyphus\"\n",
        "\n",
        "For this week's assignment, I have decided to train the GPT2 to output absurdism philosophy writings in the style of the French philosopher Albert Camus. My first week's poem was written by him, so I thought why not try to continue his works of art -- though artificially :D It is also my first time using a ML algorithm, so I have been very excited to try!\n",
        "\n",
        "Some of the challenges that I have encountered is tailoring the input data for the GPT2. Most of the time I have encountered an error saying that my dataset files are too small, so I have spent quite a lot of time trying to manipulate the text file. Right now it takes a lot of time to generate the output (I am still waiting on the output). Hopefully it's good!\n",
        "\n",
        "[5 minutes later] Well, nevermind, here is what the first sample looks like lol:\n",
        "---\n",
        "======== SAMPLE 1 ========\n",
        "\\'\\'\\'\\');\\`\\'<\\/><\\/><\\/><\\/><\\/><\\/ /\\ \\/\\/\\ \\/\\ \\/\\ \\/\\ \\/\\ \" \\/\\ \\/\\ \\/\\ \\/\\ \\/\\ \\/\\ \\/\\ \\/\\ \\/\\ \\/ \\/\\ \\/ \\/\\ \\/ \\/ \\/ \\/ \\/ \\/ \\/ \\/ \\/ \\/ \\/ \\/ \\\n",
        "\n",
        "---\n",
        "[Update] The rest of the outputs aren't that bad!!!\n",
        "\n",
        "======== SAMPLE 2 ========\n",
        "\n",
        "The first two are not as important as the third. The rest must be studied. I'll explain the three in this essay (1). It is the same thing that counts, the same thing that counts in the general idea of the essay. If an essay on the mind is to be good, it must contain a good deal of logical content. You need to know what we mean when we speak of the mind, and to be able to distinguish it from all the elements\n",
        "\n",
        "---\n",
        "======== SAMPLE 3 ========\n",
        "\n",
        "In the words of the apostle: 'There is no good, and there is no ill, from it.''And from it comes evil.' There comes evil in us, evil that escapes even our greatest effort.' Evil that takes place in us, as with us, and as with the rest, is something which we can see in the light of history. Evil which makes itself felt must always be treated with the greatest care,' but in the course of a long illness it can\n",
        "\n",
        "---\n",
        "======== SAMPLE 4 ========\n",
        "\n",
        "I was very proud of myself for the first time. As I was, at the very outset, conscious of an impossible truth, I tried to ignore it for the time being and to accept it only as a truth of this world. What am I saying, then, that this is not easy? This is something to be done. For the moment, let us say that we do not deny the possibility of knowing. On the contrary, we do not deny the validity of experience. Nor do we deny"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XdISMn1HSk53",
        "outputId": "195bd90c-842f-431c-a421-d90213bfe021"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "gpt2.download_gpt2(model_name=\"355M\")\n",
        "\n",
        "run_name = \"gpt_uploaded\"\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_name = list(uploaded.keys())[0]\n",
        "print(\"Received file \" + file_name)\n",
        "\n",
        "tf.reset_default_graph() # Reseting allows us to finetune multiple times\n",
        "                         # Run this cell again for more finetuning\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "steps = 100 # Number of times to train\n",
        "sample_every = 10 # Ask the model to generate \"original\" text as we train so we can\n",
        "                  # see the progress - the generated text should start to match\n",
        "                  # our sample text.\n",
        "sample_length = 100 # How long of sample text to generate\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              checkpoint_dir = 'checkpoint',\n",
        "              steps=steps,\n",
        "              run_name=run_name,\n",
        "              print_every=1,\n",
        "              sample_every=sample_every, \n",
        "              sample_length=sample_length,\n",
        "              )\n",
        "\n",
        "gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"\"\"\n",
        "My dear, in the midst of hate, I found there was, within me, an invincible love.\n",
        "In the midst of tears, I found there was, within me, an invincible smile.\n",
        "In the midst of chaos, I found there was, within me, an invincible calm.\n",
        "I realized, through it all, that…\n",
        "\n",
        "In the midst of winter, I found there was, within me, an invincible summer.\n",
        "And that makes me happy.\n",
        "\n",
        "For it says that no matter how hard the world pushes against me,\n",
        "within me, there’s something stronger-\n",
        "something better, pushing right back.\n",
        "\n",
        "\"\"\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 303Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 68.1Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 416Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:07, 182Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 206Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 84.2Mit/s]                                                \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 128Mit/s]                                                       \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-af29f221-7397-4569-8323-c8bc73a04377\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-af29f221-7397-4569-8323-c8bc73a04377\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving absurdism.rtf to absurdism (1).rtf\n",
            "Received file absurdism.rtf\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 23364 tokens\n",
            "Training...\n",
            "[1 | 99.97] loss=3.71 avg=3.71\n",
            "[2 | 187.14] loss=3.77 avg=3.74\n",
            "[3 | 274.94] loss=3.47 avg=3.65\n",
            "[4 | 362.04] loss=3.83 avg=3.69\n",
            "[5 | 449.91] loss=3.88 avg=3.73\n",
            "[6 | 537.78] loss=3.43 avg=3.68\n",
            "[7 | 625.04] loss=3.67 avg=3.68\n",
            "[8 | 712.60] loss=3.36 avg=3.64\n",
            "[9 | 800.41] loss=3.65 avg=3.64\n",
            "[10 | 888.57] loss=3.39 avg=3.61\n",
            "======== SAMPLE 1 ========\n",
            " absolute-minded man.\n",
            "The first two are not as important as the third. The rest must be studied. I'll explain the three in this essay (1). It is the same thing that counts, the same thing that counts in the general idea of the essay. If an essay on the mind is to be good, it must contain a good deal of logical content. You need to know what we mean when we speak of the mind, and to be able to distinguish it from all the elements\n",
            "\n",
            "[11 | 997.80] loss=3.47 avg=3.60\n",
            "[12 | 1085.41] loss=3.90 avg=3.63\n",
            "[13 | 1173.13] loss=3.37 avg=3.60\n",
            "[14 | 1260.90] loss=2.67 avg=3.53\n",
            "[15 | 1349.04] loss=3.01 avg=3.50\n",
            "[16 | 1436.99] loss=2.76 avg=3.45\n",
            "[17 | 1524.99] loss=2.68 avg=3.40\n",
            "[18 | 1613.03] loss=2.75 avg=3.36\n",
            "[19 | 1700.35] loss=3.32 avg=3.36\n",
            "[20 | 1788.51] loss=3.34 avg=3.36\n",
            "======== SAMPLE 1 ========\n",
            " humiliated by their fate. In the words of the apostle: 'There is no good, and there is no ill, from it.''And from it comes evil.' There comes evil in us, evil that escapes even our greatest effort.' Evil that takes place in us, as with us, and as with the rest, is something which we can see in the light of history. Evil which makes itself felt must always be treated with the greatest care,' but in the course of a long illness it can\n",
            "\n",
            "[21 | 1892.87] loss=3.70 avg=3.37\n",
            "[22 | 1980.45] loss=2.28 avg=3.32\n",
            "[23 | 2068.24] loss=2.29 avg=3.27\n",
            "[24 | 2155.60] loss=2.87 avg=3.25\n",
            "[25 | 2242.90] loss=2.67 avg=3.22\n",
            "[26 | 2329.56] loss=2.50 avg=3.19\n",
            "[27 | 2416.29] loss=2.23 avg=3.15\n",
            "[28 | 2503.96] loss=3.41 avg=3.16\n",
            "[29 | 2590.59] loss=3.12 avg=3.16\n",
            "[30 | 2677.48] loss=2.14 avg=3.12\n",
            "======== SAMPLE 1 ========\n",
            " I was very proud of myself for the first time. As I was, at the very outset, conscious of an impossible truth, I tried to ignore it for the time being and to accept it only as a truth of this world. What am I saying, then, that this is not easy? This is something to be done. For the moment, let us say that we do not deny the possibility of knowing. On the contrary, we do not deny the validity of experience. Nor do we deny\n",
            "\n",
            "[31 | 2781.03] loss=2.30 avg=3.09\n",
            "[32 | 2867.88] loss=2.32 avg=3.06\n",
            "[33 | 2954.49] loss=3.48 avg=3.08\n",
            "[34 | 3041.43] loss=2.04 avg=3.04\n",
            "[35 | 3128.30] loss=3.80 avg=3.07\n",
            "[36 | 3215.43] loss=1.71 avg=3.02\n",
            "[37 | 3302.75] loss=1.84 avg=2.98\n",
            "[38 | 3390.95] loss=2.13 avg=2.96\n",
            "[39 | 3477.79] loss=2.52 avg=2.94\n",
            "[40 | 3564.64] loss=1.35 avg=2.90\n",
            "======== SAMPLE 1 ========\n",
            " living in fear. The more fearful a man becomes, the more the fear of death becomes his life, and the more he feels that it is the only reality. And this, dear reader, is the tragedy of Dante's Paradiso. At the beginning of the Inferno, the Hellenes are told there is nothing so dangerous as death. But this absurd and disinterestedness is the only reality before them. They become so terrified that they are reduced to the same crime as the Jews and the Christians themselves\n",
            "\n",
            "[41 | 3667.51] loss=3.18 avg=2.90\n",
            "[42 | 3755.12] loss=1.83 avg=2.87\n",
            "[43 | 3842.49] loss=3.61 avg=2.89\n",
            "[44 | 3930.50] loss=1.52 avg=2.86\n",
            "[45 | 4018.05] loss=1.39 avg=2.82\n",
            "[46 | 4105.31] loss=2.43 avg=2.81\n",
            "[47 | 4192.93] loss=2.74 avg=2.80\n",
            "[48 | 4280.87] loss=2.60 avg=2.80\n",
            "[49 | 4369.26] loss=2.53 avg=2.79\n",
            "[50 | 4457.06] loss=1.63 avg=2.76\n",
            "======== SAMPLE 1 ========\n",
            " to be used against them by the world. They are not rational entities but emotional, linguistic processes that are conditioned in the individual by life and the world around him. Rational beings are also alienated, i.e., they do not apprehend their own existence. Here the irrational experiences something quite new — death. The suddenness with which it departs in the life it leads and the sudden influence it exerts on the life that it abides in astonish, terror, and disgust.\\\n",
            "\\pard\n",
            "\n",
            "[51 | 4561.26] loss=2.02 avg=2.74\n",
            "[52 | 4648.95] loss=2.91 avg=2.75\n",
            "[53 | 4736.24] loss=1.38 avg=2.71\n",
            "[54 | 4823.56] loss=2.13 avg=2.70\n",
            "[55 | 4910.94] loss=3.10 avg=2.71\n",
            "[56 | 4998.03] loss=2.03 avg=2.69\n",
            "[57 | 5085.21] loss=1.95 avg=2.68\n",
            "[58 | 5172.06] loss=1.10 avg=2.64\n",
            "[59 | 5259.66] loss=1.80 avg=2.62\n",
            "[60 | 5347.62] loss=1.37 avg=2.59\n",
            "======== SAMPLE 1 ========\n",
            "org?t=2,991\n",
            "\n",
            "\n",
            "In sum, on the one hand the mind offers a solution, and on the other it suppresses its negation. Thus Kierkegaard says: 'The dogmas of religion, the creeds of the mind and the convictions of the heart, are one and the same. They imply one another. They are bound together by their relation. Their negation, my silence, is my escape. I can no longer hope in vain. I have to\n",
            "\n",
            "[61 | 5450.89] loss=0.81 avg=2.56\n",
            "[62 | 5538.09] loss=1.81 avg=2.54\n",
            "[63 | 5625.19] loss=1.66 avg=2.52\n",
            "[64 | 5712.41] loss=2.65 avg=2.52\n",
            "[65 | 5799.98] loss=1.24 avg=2.50\n",
            "[66 | 5888.55] loss=1.19 avg=2.47\n",
            "[67 | 5976.62] loss=1.90 avg=2.46\n",
            "[68 | 6064.84] loss=2.87 avg=2.47\n",
            "[69 | 6155.94] loss=1.22 avg=2.44\n",
            "[70 | 6243.57] loss=1.91 avg=2.43\n",
            "======== SAMPLE 1 ========\n",
            "omet is the first to arrive. It is the first that takes an affirmative position and that does what is expected of it. Nothing else is true. All that is true is meaningless, except that it affects our perception. The whole logic of this work is to bring to light that state of the mind in which the paradoxes are meant to be acted out.\\\n",
            "{\\field{\\*\\fldinst{HYPERLINK \"https://theanarchistlibrary.org/library/al\n",
            "\n",
            "[71 | 6350.39] loss=1.83 avg=2.42\n",
            "[72 | 6438.18] loss=2.07 avg=2.41\n",
            "[73 | 6526.31] loss=1.18 avg=2.39\n",
            "[74 | 6614.29] loss=1.30 avg=2.37\n",
            "[75 | 6701.72] loss=0.80 avg=2.34\n",
            "[76 | 6788.76] loss=1.74 avg=2.33\n",
            "[77 | 6875.61] loss=0.64 avg=2.30\n",
            "[78 | 6962.05] loss=1.70 avg=2.29\n",
            "[79 | 7048.36] loss=1.80 avg=2.28\n",
            "[80 | 7134.85] loss=0.54 avg=2.24\n",
            "======== SAMPLE 1 ========\n",
            " to the contrary, to the exclusion of all other possible judgments. I can thus understand the appeal of a statement like 'There are but two truths': both are true. This is my fourth argument: that is all I can formulate in terms of what can be determined by the facts. As for the question itself, I am satisfied with the answer 'yes.'\\\n",
            "If, at this point, we consider the case as a whole, we shall be faced with the same objection again. This time we\n",
            "\n",
            "[81 | 7237.92] loss=0.87 avg=2.22\n",
            "[82 | 7324.56] loss=1.89 avg=2.21\n",
            "[83 | 7411.08] loss=3.59 avg=2.24\n",
            "[84 | 7497.39] loss=1.08 avg=2.22\n",
            "[85 | 7583.63] loss=1.33 avg=2.20\n",
            "[86 | 7670.06] loss=1.35 avg=2.19\n",
            "[87 | 7756.30] loss=1.90 avg=2.18\n",
            "[88 | 7842.81] loss=1.50 avg=2.17\n",
            "[89 | 7929.00] loss=0.89 avg=2.15\n",
            "[90 | 8015.92] loss=1.61 avg=2.14\n",
            "======== SAMPLE 1 ========\n",
            "800970099001\n",
            "After using the terms above, it becomes clear how meaningless were their results, and how little interest they had in their subjects. It was a question of 'how many years' or 'how fast', not of 'how many scientists died', but of 'how many scientists in a long period of time'.\\\n",
            "What can be claimed to be a settled controversy is the one which concerns us at present. On the one hand it is assumed that the intellect has the possibility to\n",
            "\n",
            "[91 | 8117.34] loss=0.71 avg=2.12\n",
            "[92 | 8203.59] loss=1.00 avg=2.10\n",
            "[93 | 8291.03] loss=2.97 avg=2.11\n",
            "[94 | 8377.64] loss=0.77 avg=2.09\n",
            "[95 | 8465.94] loss=0.82 avg=2.07\n",
            "[96 | 8552.06] loss=0.99 avg=2.05\n",
            "[97 | 8638.16] loss=0.89 avg=2.03\n",
            "[98 | 8724.48] loss=0.88 avg=2.02\n",
            "[99 | 8810.78] loss=2.35 avg=2.02\n",
            "[100 | 8896.76] loss=0.51 avg=2.00\n",
            "Saving checkpoint/gpt_uploaded/model-100\n",
            "My dear, in the midst of hate, I found there was, within me, an invincible love.\n",
            "In the midst of tears, I found there was, within me, an invincible smile.\n",
            "In the midst of chaos, I found there was, within me, an invincible calm.\n",
            "I realized, through it all, that…\n",
            "\n",
            "In the midst of winter, I found there was, within me, an invincible summer.\n",
            "And that makes me happy.\n",
            "\n",
            "For it says that no matter how hard the world pushes against me,\n",
            "within me, there’s something stronger-\n",
            "something better, pushing right back.\n",
            "\n",
            "\n",
            "And you are to me what springwater is to you. You take me for a wild and irreparable and permanent and limited being, and you give me the choice between this uncaring, cold universe and the immense, passionate but limited universe of which I am a part. You give me the choice between a universe in which I have no future and in which nothing is possible but everything is given me and in which everything would be given me but for the world and the world only because it is the world. And you make me imagine that this universe has a future. You give me the universe of dreams and providence and reason and the rest. And you make me imagine that this universe has a destiny. You take me back to the very beginning of the universe and you give me the choice between the universe of my dreams and the universe of this universe. You make me imagine that this universe has a history and that its laws were governed by regular processes. You give me the universe of reason and the universe of experience. You take me back to the very beginning of the universe and you give me the choice between the universe of my mind and the universe of this universe. You make me imagine that this universe had a destiny and that its character\n",
            "====================\n",
            "My dear, in the midst of hate, I found there was, within me, an invincible love.\n",
            "In the midst of tears, I found there was, within me, an invincible smile.\n",
            "In the midst of chaos, I found there was, within me, an invincible calm.\n",
            "I realized, through it all, that…\n",
            "\n",
            "In the midst of winter, I found there was, within me, an invincible summer.\n",
            "And that makes me happy.\n",
            "\n",
            "For it says that no matter how hard the world pushes against me,\n",
            "within me, there’s something stronger-\n",
            "something better, pushing right back.\n",
            "\n",
            "\n",
            "And what is it?\n",
            "In the beginning, I saw nothing.\n",
            "\n",
            "But that very silence that is the first sign of a feeling,‑\n",
            "\n",
            "that very thing that signifies nothing‑\n",
            "\n",
            "is also empty.\n",
            "\n",
            "And what is that feeling that signifies nothing?\n",
            "\n",
            "Nothingness.\n",
            "\n",
            "It is not the absence of a thing, which is my first thought, but rather the absence of a thought. I see that when I try to make a thing stand for itself, that empty space in which it is felt to have no meaning. I see that when I try to define a reality outside my own, this empty universe in which it seems so simple, this cosmos in which it seems so foreign.\n",
            "\n",
            "And what does that universe mean? It must mean that the laws of gravity, the tension in the atom, the repulsion in the electron, the repulsion in the electron-positron system, the repulsion in the subatomic particle, the attraction between an electron and a proton, the repulsion in the atom, and the repulsion in the atom itself, exist in a universal law of nature, are not separable, and that they contribute to the tension of the atom.\n",
            "\n",
            "====================\n",
            "My dear, in the midst of hate, I found there was, within me, an invincible love.\n",
            "In the midst of tears, I found there was, within me, an invincible smile.\n",
            "In the midst of chaos, I found there was, within me, an invincible calm.\n",
            "I realized, through it all, that…\n",
            "\n",
            "In the midst of winter, I found there was, within me, an invincible summer.\n",
            "And that makes me happy.\n",
            "\n",
            "For it says that no matter how hard the world pushes against me,\n",
            "within me, there’s something stronger-\n",
            "something better, pushing right back.\n",
            "\n",
            "\n",
            "You see, my dear, this love is mine. It is yours only if you like. If you do not, that is all that can be said. For me, from the first to the last sentence, there is a plea. A wager. A reconciliation. An admission. A repudiation. A denial. A refusal to be compared. Anything else would mean hypocrisy. I shall not pay any attention to it. I have already made up my mind. If you insist on drawing a conclusion, if you conclude that this is not enough, then you have already cheated. If you insist on drawing a conclusion that you think justifies your hatred‬then you have already cheated. And you can only cheat again and again and again until you get to that point at which nothing justifies hatred. At which that hatred turns toward death. At which the conscience feels free to speak its truth. At which the heart can feel free to move. At which the whole matter is over and all that is left is to establish the relationship that will last.\n",
            "\n",
            "\n",
            "What I am saying is that your loyalty does not depend on my liking or liking on your loyalty depends on the truth of your accusations. What I am saying is that a lie will not\n",
            "====================\n",
            "My dear, in the midst of hate, I found there was, within me, an invincible love.\n",
            "In the midst of tears, I found there was, within me, an invincible smile.\n",
            "In the midst of chaos, I found there was, within me, an invincible calm.\n",
            "I realized, through it all, that…\n",
            "\n",
            "In the midst of winter, I found there was, within me, an invincible summer.\n",
            "And that makes me happy.\n",
            "\n",
            "For it says that no matter how hard the world pushes against me,\n",
            "within me, there’s something stronger-\n",
            "something better, pushing right back.\n",
            "\n",
            "\n",
            "In the midst of summer, I found there was, within me, the reason for everything.\n",
            "\n",
            "And that makes me happy.\n",
            "\n",
            "For it says that no matter how hard the world pushes against me,\n",
            "\n",
            "within me, there is something better,\n",
            "\n",
            "pulling in.\n",
            "\n",
            "I.e.\n",
            "\n",
            "In the summer of my love, how can I fail to reach the goal of my heart,\n",
            "\n",
            "how can I fail to make of that eternal logic of mine\n",
            "\n",
            "that irrational passion which, in its turn, invokes up all the passions in me‒even the stupid ones‒and sets them against each other?\n",
            "\n",
            "If I try to reach it by indirect methods, if I try to evoke out the feeling of the irrational, I shall not succeed. For the irrational is not in me. It is alien. It is distant. It does not exist there. It is not even a principle. It is merely an illusion. I can therefore say that the irrational is not in the world‒that is all I can say. It exists only in the act of my imagining it, in the constant opposition it makes between my intention and the realization that is given me. And if\n",
            "====================\n",
            "My dear, in the midst of hate, I found there was, within me, an invincible love.\n",
            "In the midst of tears, I found there was, within me, an invincible smile.\n",
            "In the midst of chaos, I found there was, within me, an invincible calm.\n",
            "I realized, through it all, that…\n",
            "\n",
            "In the midst of winter, I found there was, within me, an invincible summer.\n",
            "And that makes me happy.\n",
            "\n",
            "For it says that no matter how hard the world pushes against me,\n",
            "within me, there’s something stronger-\n",
            "something better, pushing right back.\n",
            "\n",
            "\n",
            "And here are these mountains and in my heart there is this desire‒this urge to scale them, to seize them and to turn them upside down. And here is this world in which I mustered up the courage to desire.\n",
            "\n",
            "At this juncture, I ask you to imagine a different world. You tell me that this world has a God. And here I am mistaken. I was born and raised in a religious home. I know that in that home there is no God. I was not even born yet aware of his existence. But you tell me that this world has a creator. And here I am again. You explain: \\'93There is no god but man\\'94 and that creator is himself. So that is what I shall call him. And you add: \\'93He is the way he is because he is not a god.\\'94 And you remind me of this paradox: \\'93God is not all that, and man is all that.\\'94 \\'93The way seems to me,\\'94 you say, \\'93therefore,\\'94 the way seems to be God.\\'94 \\'93But it is not so.\\'94 This world is but a dream.\\'94\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}